%!TEX root = main.tex

We have compared OSTRICH+ with the state-of-the-art solvers on a wide range of benchmarks. The solvers we considered include CVC4, Z3-str3, two variants of Trau, namely Trau+ and Z3-Trau, and SLENT. 

We have implemented our decision procedure for path feasibility based on the tool OSTRICH, which is built on top of the SMT solver Princess \cite{}. 
%
%OSTRICH implements the optimised
%decision procedure for string functions as described in Section 5.1 (i.e. using distributivity of regular
%constraints across pre-images of functions) and has built-in support for concatenation, reverse, FFT,
%and replaceAll. Moreover, since the optimisation only requires that string operations are functional,
%we can also support additional functions that satisfy RegInvRel, such as replacee which replaces
%only the first (leftmost and longest) match of a regular expression. OSTRICH is extensible and new
%string functions can be added quite simply (Section 6.3).
%Our implementation adds a new theory solver for conjunctive formulas representing path
%feasibility problems to Princess (Section 6.1). This means that we support disjunction as well as
%conjunction in formulas, as long as every conjunction of literals fed to the theory solver corresponds
%to a path feasibility problem. OSTRICH also implements a number of optimisations to efficiently
%compute pre-images of relevant functions (Section 6.2). OSTRICH is entirely written in Scala and is
%open-source. We report on our experiments with OSTRICH in Section 6.4. The tool is available on
%GitHub6.  


\subsection{Benchmarks}
 
We have compared our tool with a number of existing solvers on a wide range of benchmarks. In
particular, we compared  with CVC4 1.6 \cite{}, SLOTH \cite{},
and Z3 configured to use the Z3-str3 string solver \cite{}. 

%We considered several sets
%of benchmarks which are described in the next sub-section. The results are given in Section 6.4.2.
%
%
%In [Holík et al. 2018] SLOTH was compared with S3P [Trinh et al. 2016] where inconsistent
%behaviour was reported. We contacted the S3P authors who report that the current code is unsupported;
%moreover, S3P is being integrated with Z3. Hence, we do not compare with this tool.
%
%
%The first set of benchmarks we call \textbf{Transducer}. It combines the benchmark
%sets of Stranger [Yu et al. 2010] and the mutation XSS benchmarks of [Lin and Barceló 2016]. The
%first (sub-)set appeared in [Holík et al. 2018] and contains instances manually derived from PHP
%programs taken from the website of Stranger [Yu et al. 2010]. It contains 10 formulae (5 sat, 5
%unsat) each testing for the absence of the vulnerability pattern .*<script.* in the program output.
%These formulae contain between 7 and 42 variables, with an average of 21. The number of atomic
%constraints ranges between 7 and 38 and averages 18. These examples use disjunction, conjunction,
%regular constraints, and concatenation, replaceAll. They also contain several one-way functional
%transducers (defined in SMTLIB in [Holík et al. 2018]) encoding functions such as addslashes and
%trim used by the programs. Note that transducers have been known for some time to be a good
%framework for specifying sanitisers and browser transductions (e.g., see the works by Minamide,
%Veanes, Saxena, and others [D’Antoni and Veanes 2013; Hooimeijer et al. 2011; Minamide 2005;
%Weinberger et al. 2011]), and a library of transducer specifications for such functions is available
%(e.g. see the language BEK [Hooimeijer et al. 2011]).
%
%The second (sub-)set was used by [Holík et al. 2018; Lin and Barceló 2016] and consists of 8
%formulae taken from [Kern 2014; Lin and Barceló 2016]. These examples explore mutation XSS
%vulnerabilities in JavaScript programs. They contain between 9 and 12 variables, averaging 9.75, and
%9-13 atomic constraints, with an average of 10.5. They use conjunctions, regular constraints, concatenation,
%replaceAll, and transducers providing functions such as htmlEscape and escapeString.
%Our next set of benchmarks, SLOG, came from the SLOG tool [Wang et al. 2016] and consist of
%3,392 instances. They are derived from the security analysis of real web applications and contain 1-
%211 string variables (average 6.5) and 1-182 atomic formula (average 5.8).We split these benchmarks
%into two sets SLOG (replace) and SLOG (replaceall). Each use conjunction, disjunction, regular
%constraints, and concatenation. The set SLOG (replace) contains 3,391 instances and uses replace.
%SLOG (replaceall) contains 120 instances using the replaceAll operation.
%
%
%Our next set of benchmarks Kaluza is the well-known set of Kaluza benchmarks [Saxena et al.
%2010] restricted to those instances which satisfy our semantic conditions (roughly 80\% of the
%benchmarks). Kaluza contains concatenation, regular constraints, and length constraints, most of
%which admit regular monadic decomposition. There are 37,090 such benchmarks (28 032 sat).
%We also considered the benchmark set of [Chen 2018a,b]. This contains 42 hand-crafted benchmarks
%using regular constraints, concatenation, and replaceAll with variables in both argument
%positions. The benchmarks contain 3-7 string variables and 3-9 atomic constraints.
% 

 

\paragraph*{Benchmark suites.} We consider the following four benchmark suites.

The first benchmark suite {\transducerbench+} is generated from the {\transducerbench} benchmark suite of OSTRICH \cite{CHL+19}.  The {\transducerbench} suite involves the following seven transducers: toUpperCase and its dual toLowerCase, htmlEscape\footnote{\url{https://github.com/google/closure-library/blob/master/closure/goog/string/string.js#L549}} and its dual htmlUnescape, escapeString\footnote{\url{https://github.com/google/closure-library/blob/master/closure/goog/string/string.js#L878}}, addslashes\footnote{\url{http://php.net/manual/en/function.addslashes.php}}, and trim\footnote{\url{https://www.php.net/manual/en/function.trim.php}}. The {\transducerbench+} suite is generated from these transducers by encoding the idempotence, duality, commutativity, and equivalence\footnote{These problems have been investigated for transducers in \cite{BEK}.} problems into the path feasibility of {\slint} programs as follows:
\begin{description}
\item[Idempotence.] For each FFT $\NFT$,  we encode the non-idempotence of $\NFT$, namely deciding whether $\exists x.\ \NFT(\NFT(x)) \neq \NFT(x)$, into the path feasibility of the {\slint} program $y:=\NFT(x); z:=\NFT(y); S_{y \neq z}$, where $y$ and $z$ are two fresh string variables, and $S_{y \neq z}$ is the {\slint} program encoding $y \neq z$, which uses $\length$ and $\charat$ (see Section~\ref{sec:logic} for the details of $S_{y \neq z}$).
%
\item[Duality.] For each pair of distinct FFTs $\NFT_1$ and $\NFT_2$, we encode the non-duality of $\NFT_1$ and $\NFT_2$, namely deciding whether $\exists x.\ \NFT_2(\NFT_1(x)) \neq x$, into the path feasibility of the {\slint} program $y:=\NFT_1(x); z: = \NFT_2(y); S_{x \neq z}$.
%
\item[Commutativity.] For each pair of distinct FFTs $\NFT_1$ and $\NFT_2$, we encode the non-commutativity of $\NFT_1$ and $\NFT_2$, namely deciding whether $\exists x.\ \NFT_2(\NFT_1(x)) \neq \NFT_1(\NFT_2(x))$, into the path feasibility of the {\slint} program $y:=\NFT_1(x); z: = \NFT_2(y); y':= \NFT_2(x); z': = \NFT_1(y'); S_{z \neq z'}$.
%
\item[Equivalence.] For each pair of distinct FFTs $\NFT_1$ and $\NFT_2$, we encode the non-equivalence of $\NFT_1$ and $\NFT_2$, namely deciding whether $\exists x.\ \NFT_1(x) \neq \NFT_2(x)$, into the path feasibility of the {\slint} program $y:=\NFT_1(x); z: = \NFT_2(x); S_{y \neq z}$.
%
\end{description}
In total, we get 70 ($7+21+21+21$) \zhilin{to be checked} instances for the {\transducerbench+} suite. 

The second benchmark suite is the {\pyexbench} suite from \cite{ReynoldsWBBLT17}, which comprises \zhilin{xxx} instances. 
This suite is derived from PyEx, a symbolic executor for Python programs. The {\pyexbench} suite was generated by the CVC4 group on four popular Python packages: httplib2, pip, pymongo, and requests. These instances use regular constraints, concatenation, $\length$, $\substring$, and $\indexof$ functions. Moreover, the {\pyexbench} suite is further divided into the three sub-suites: {\pyextdbench} comprising \zhilin{xxx} instances, {\pyexztbench} comprising \zhilin{xxx} instances, and {\pyexzzbench} comprising \zhilin{xxx} instances.

The third benchmark suite {\slogbench} is adapted from the SLOG benchmark suite used by the SLOG tool~\cite{fang-yu-circuits} and has 3,392 instances \zhilin{the number to be checked}. 
%The SLOG are derived from the security analysis of real web applications and contain 1-211 string variables (average 6.5) and 1-182 atomic formula (average 5.8).
The SLOG benchmark suite contains only the string data type and no integer data type.
In order to evaluate OSTRICH+ more faithfully, we adapt each SLOG instance into one containing the integer data type, by choosing an output string variable\footnote{A string variable is called the output variable if it occurs in the left-hand side of an assignment statement, but does not appear in the right-hand sides of the assignment statements}, say $x$, and adding the statement $\ASSERT{2\ \indexof_{a}(x, 0) < \length(x)}$ for some $a \in \Sigma$.
% and $c \in \Nat$ with $c > 1$.
We split the {\slogbench} benchmark suite into two sub-suites \slogbenchr\ and \slogbenchra, which comprises 3,391 instances \zhilin{the number to be checked} and 120 instances \zhilin{the number to be checked} respectively. Both  \slogbenchr\ and \slogbenchra\ use regular constraints and concatenation. The difference is in that \slogbenchr\ uses the $\replace$ function (replacing the first occurrence), while \slogbenchra\ uses the $\replaceall$ function (replacing all occurrences).
%Each use conjunction, disjunction, regular constraints, and concatenation.
%The \slogbenchr\ sub-suite contains 3,391 instances \zhilin{the number to be checked}, while \slogbenchra\ sub-suite contains 120 instances \zhilin{the number to be checked}.


The fourth benchmark suite {\kaluzabench} is the well-known \emph{Kaluza} benchmark suite~\cite{Berkeley-JavaScript}.
{\kaluzabench} contains 47,284 instances. They use regular constraints, concatenation, and $\length$ function.





\paragraph*{Experimental results.}




%$z_1:=\charat(x,i); z_2 := \charat(y,i); \ASSERT{\bigvee_{a \in \Sigma} (z_1 \in \NFA_a \wedge z_2 \in \NFA_{\Sigma^* \setminus a})}$, where $\NFA_a$ is the NFA accepting $\{a\}$ and $\NFA_{\Sigma^* \setminus a}$ is the NFA accepting $\Sigma^* \setminus \{a\}$.

comparison

CVC4

Z3-STR3

SLENT

TRAU+ or Z3-TRAU

\definecolor{Gray}{gray}{0.9}
%\newcolumntype{g}{>{\columncolor{Gray}}c}
\begin{table}[htbp]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
& &  CVC4 & Z3-str3 & SLENT & TRAU+ & Z3-TRAU & Ostrich+\\
\hline
\multirow{4}{*}{\transducerbench(xxx)} & \cellcolor{Gray} sat & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray}\\
\cline{2-8}
 & unsat &  &  &  &  & &\\
\cline{2-8}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} &\cellcolor{Gray} &\cellcolor{Gray} \\
\cline{2-8}
 & error/unknown &  &  &  &  & &\\
\hline
\multirow{4}{*}{\pyextdbench(5569)} & \cellcolor{Gray} sat & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray}\\
\cline{2-8}
 & unsat &  &  &  &  & &\\
\cline{2-8}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} &\cellcolor{Gray} &\cellcolor{Gray} \\
\cline{2-8}
 & error/unknown &  &  &  &  & &\\
\hline
\multirow{4}{*}{\pyexztbench(8414)} & \cellcolor{Gray} sat & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray}\\
\cline{2-8}
 & unsat &  &  &  &  & &\\
\cline{2-8}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} &\cellcolor{Gray} &\cellcolor{Gray} \\
\cline{2-8}
 & error/unknown &  &  &  &  & &\\
\hline
\multirow{4}{*}{\pyexzzbench(11438)} & \cellcolor{Gray} sat & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray}\\
\cline{2-8}
 & unsat &  &  &  &  & &\\
\cline{2-8}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} &\cellcolor{Gray} &\cellcolor{Gray} \\
\cline{2-8}
 & error/unknown &  &  &  &  & &\\
\hline
\multirow{4}{*}{\slogbenchr(3391)} & \cellcolor{Gray} sat & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} \\
\cline{2-8}
 & unsat &  &  &  &  & &\\
\cline{2-8}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} &\cellcolor{Gray} &\cellcolor{Gray} \\
\cline{2-8}
 & error/unknown &  &  &  &  & &\\
\hline
\multirow{4}{*}{\slogbenchra(120)} & \cellcolor{Gray} sat & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray}\\
\cline{2-8}
 & unsat &  &  &  &  & &\\
\cline{2-8}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} &\cellcolor{Gray} &\cellcolor{Gray} \\
\cline{2-8}
 & error/unknown &  &  &  &  & &\\
\hline
\multirow{4}{*}{\kaluzabench(47284)} & \cellcolor{Gray} sat & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray}\\
\cline{2-8}
 & unsat &  &  &  &  & &\\
\cline{2-8}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} &\cellcolor{Gray} &\cellcolor{Gray} \\
\cline{2-8}
 & error/unknown &  &  &  &  & &\\
\hline
\multirow{2}{*}{Total(xxx)} & \cellcolor{Gray} solved & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray}\\
\cline{2-8}
 & \cellcolor{Gray}  unsolved & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} &\cellcolor{Gray} &\cellcolor{Gray} \\
\hline
\end{tabular}
\end{center}
\caption{Experimental results}
\label{tab-experiment}
\end{table}%



32-core-Intel-Xeon-E5-2690-@2.90GHz
8G memory

unsat------------------

totaltimeout = 30

nmuxvtimout = 30

total num : 0-3320

total-time: 10460 s

averange-time: 3.15 s 

sat: $0 / 0\%$

unsat: $2840 / 85.54\%$

unknown: $351 / 10.57\%$

timeout: $127 / 3.83\%$

parser error: $2 / 0.06\%$

sat--------------------

totaltimeout = 30

nmuxvtimout = 30

register bound = 30

total num : 0-18852

total time: 63840 s

averange-time: 3.39 s 

sat: $17668 / 93.72\%$

unsat: $0 / 0\%$


unknown: $1172 / 6.22\%$

timeout: $11 / 0.06\%$

parser error: $2 / 0.01\%$