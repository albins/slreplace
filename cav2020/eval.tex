%!TEX root = main.tex

We have compared {\ostrich}+ with the state-of-the-art solvers on a wide range of benchmarks. The solvers we considered include {\cvc} \cite{cvc4}, {\zthree} \cite{Z3-str}, and two latest variants of Trau (i.e., {\trauplus} \cite{AbdullaA+19} and {\zthreetrau} \cite{Z3-trau}).
% and SLENT \cite{WC+18}. 

 %
%OSTRICH implements the optimised
%decision procedure for string functions as described in Section 5.1 (i.e. using distributivity of regular
%constraints across pre-images of functions) and has built-in support for concatenation, reverse, FFT,
%and replaceAll. Moreover, since the optimisation only requires that string operations are functional,
%we can also support additional functions that satisfy RegInvRel, such as replacee which replaces
%only the first (leftmost and longest) match of a regular expression. OSTRICH is extensible and new
%string functions can be added quite simply (Section 6.3).
%Our implementation adds a new theory solver for conjunctive formulas representing path
%feasibility problems to Princess (Section 6.1). This means that we support disjunction as well as
%conjunction in formulas, as long as every conjunction of literals fed to the theory solver corresponds
%to a path feasibility problem. OSTRICH also implements a number of optimisations to efficiently
%compute pre-images of relevant functions (Section 6.2). OSTRICH is entirely written in Scala and is
%open-source. We report on our experiments with OSTRICH in Section 6.4. The tool is available on
%GitHub6.  


\subsection{Benchmarks}
 
%In
%particular, we compared  with CVC4 1.6 \cite{}, SLOTH \cite{},
%and Z3 configured to use the Z3-str3 string solver \cite{}. 

%We considered several sets
%of benchmarks which are described in the next sub-section. The results are given in Section 6.4.2.
%
%
%In [Holík et al. 2018] SLOTH was compared with S3P [Trinh et al. 2016] where inconsistent
%behaviour was reported. We contacted the S3P authors who report that the current code is unsupported;
%moreover, S3P is being integrated with Z3. Hence, we do not compare with this tool.
%
%
%The first set of benchmarks we call \textbf{Transducer}. It combines the benchmark
%sets of Stranger [Yu et al. 2010] and the mutation XSS benchmarks of [Lin and Barceló 2016]. The
%first (sub-)set appeared in [Holík et al. 2018] and contains instances manually derived from PHP
%programs taken from the website of Stranger [Yu et al. 2010]. It contains 10 formulae (5 sat, 5
%unsat) each testing for the absence of the vulnerability pattern .*<script.* in the program output.
%These formulae contain between 7 and 42 variables, with an average of 21. The number of atomic
%constraints ranges between 7 and 38 and averages 18. These examples use disjunction, conjunction,
%regular constraints, and concatenation, replaceAll. They also contain several one-way functional
%transducers (defined in SMTLIB in [Holík et al. 2018]) encoding functions such as addslashes and
%trim used by the programs. Note that transducers have been known for some time to be a good
%framework for specifying sanitisers and browser transductions (e.g., see the works by Minamide,
%Veanes, Saxena, and others [D’Antoni and Veanes 2013; Hooimeijer et al. 2011; Minamide 2005;
%Weinberger et al. 2011]), and a library of transducer specifications for such functions is available
%(e.g. see the language BEK [Hooimeijer et al. 2011]).
%
%The second (sub-)set was used by [Holík et al. 2018; Lin and Barceló 2016] and consists of 8
%formulae taken from [Kern 2014; Lin and Barceló 2016]. These examples explore mutation XSS
%vulnerabilities in JavaScript programs. They contain between 9 and 12 variables, averaging 9.75, and
%9-13 atomic constraints, with an average of 10.5. They use conjunctions, regular constraints, concatenation,
%replaceAll, and transducers providing functions such as htmlEscape and escapeString.
%Our next set of benchmarks, SLOG, came from the SLOG tool [Wang et al. 2016] and consist of
%3,392 instances. They are derived from the security analysis of real web applications and contain 1-
%211 string variables (average 6.5) and 1-182 atomic formula (average 5.8).We split these benchmarks
%into two sets SLOG (replace) and SLOG (replaceall). Each use conjunction, disjunction, regular
%constraints, and concatenation. The set SLOG (replace) contains 3,391 instances and uses replace.
%SLOG (replaceall) contains 120 instances using the replaceAll operation.
%
%
%Our next set of benchmarks Kaluza is the well-known set of Kaluza benchmarks [Saxena et al.
%2010] restricted to those instances which satisfy our semantic conditions (roughly 80\% of the
%benchmarks). Kaluza contains concatenation, regular constraints, and length constraints, most of
%which admit regular monadic decomposition. There are 37,090 such benchmarks (28 032 sat).
%We also considered the benchmark set of [Chen 2018a,b]. This contains 42 hand-crafted benchmarks
%using regular constraints, concatenation, and replaceAll with variables in both argument
%positions. The benchmarks contain 3-7 string variables and 3-9 atomic constraints.
% 

We consider the following four sets of benchmarks.

The first benchmark suite {\transducerbench+} is derived from the {\transducerbench} benchmark suite of {\ostrich} \cite{CHL+19}.  The {\transducerbench} suite involves the following seven transducers: toUpper (replacing all lowercase letters with their uppercase ones) and its dual toLower, htmlEscape \cite{htmlEscape} and its dual htmlUnescape, escapeString \cite{escapeString}, addslashes \cite{addslashes}, and trim \cite{trim}. The {\transducerbench+} suite is generated from these transducers by encoding the idempotence (given $\NFT$, whether $\forall x.\ \NFT(\NFT(x)) = \NFT(x)$), duality (given $\NFT_1$ and $\NFT_2$, whether $\forall x.\ \NFT_2(\NFT_1(x)) = x$), commutativity (given $\NFT_1$ and $\NFT_2$, whether $\forall x.\ \NFT_2(\NFT_1(x)) = \NFT_1(\NFT_2(x))$), and equivalence (given $\NFT_1$ and $\NFT_2$, whether $\forall x.\ \NFT_1(x) = \NFT_2(x)$) problems \footnote{These problems have been investigated for transducers in \cite{BEK}.} into the path feasibility of {\slint} programs. For instance, we encode the non-idempotence of $\NFT$ into the path feasibility of the {\slint} program $y:=\NFT(x); z:=\NFT(y); S_{y \neq z}$, where $y$ and $z$ are two fresh string variables, and $S_{y \neq z}$ is the {\slint} program encoding $y \neq z$, which uses $\length$ and $\charat$ (see Section~\ref{sec:logic} for the details of $S_{y \neq z}$). In total, we get 91 instances for the {\transducerbench+} benchmark suite. 
%\begin{description}
%\item[Idempotence.] For each FFT $\NFT$,  we encode the non-idempotence of $\NFT$, namely deciding whether $\exists x.\ \NFT(\NFT(x)) \neq \NFT(x)$, into the path feasibility of the {\slint} program $y:=\NFT(x); z:=\NFT(y); S_{y \neq z}$, where $y$ and $z$ are two fresh string variables, and $S_{y \neq z}$ is the {\slint} program encoding $y \neq z$, which uses $\length$ and $\charat$ (see Section~\ref{sec:logic} for the details of $S_{y \neq z}$).
%
%\item[Duality.] For each pair of distinct FFTs $\NFT_1$ and $\NFT_2$, we encode the non-duality of $\NFT_1$ and $\NFT_2$, namely deciding whether $\exists x.\ \NFT_2(\NFT_1(x)) \neq x$, into the path feasibility of the {\slint} program $y:=\NFT_1(x); z: = \NFT_2(y); S_{x \neq z}$.
%
%\item[Commutativity.] For each pair of distinct FFTs $\NFT_1$ and $\NFT_2$, we encode the non-commutativity of $\NFT_1$ and $\NFT_2$, namely deciding whether $\exists x.\ \NFT_2(\NFT_1(x)) \neq \NFT_1(\NFT_2(x))$, into the path feasibility of the {\slint} program $y:=\NFT_1(x); z: = \NFT_2(y); y':= \NFT_2(x); z': = \NFT_1(y'); S_{z \neq z'}$.
%
%\item[Equivalence.] For each pair of distinct FFTs $\NFT_1$ and $\NFT_2$, we encode the non-equivalence of $\NFT_1$ and $\NFT_2$, namely deciding whether $\exists x.\ \NFT_1(x) \neq \NFT_2(x)$, into the path feasibility of the {\slint} program $y:=\NFT_1(x); z: = \NFT_2(x); S_{y \neq z}$.
%
%\end{description}

The second benchmark suite {\slogbench} is adapted from the SLOG benchmark suite used by the SLOG tool~\cite{fang-yu-circuits} and contains 3,511 instances. 
%The SLOG are derived from the security analysis of real web applications and contain 1-211 string variables (average 6.5) and 1-182 atomic formula (average 5.8).
Since the SLOG benchmark suite does not contain the integer data type,
we obtain the {\slogbench} suite by choosing for each SLOG benchmark instance an output string variable\footnote{A string variable is called the output variable if it occurs in the left-hand side of an assignment statement, but does not appear in the right-hand sides of the assignment statements.}, say $x$, and add the statement $\ASSERT{2\ \indexof_{a}(x, 0) < \length(x)}$ for some $a \in \Sigma$.
% and $c \in \Nat$ with $c > 1$.
We further split the {\slogbench} benchmark suite into two sub-suites \slogbenchr\ and \slogbenchra, which comprises 3,391 instances and 120 instances respectively. In addition to the aforementioned $\indexof$ and $\length$ functions, both  \slogbenchr\ and \slogbenchra\ benchmarks use regular constraints and concatenation, the difference is in that {\slogbenchr} benchmarks use the $\replace$ function (replacing the first occurrence), while {\slogbenchra} benchmarks use the $\replaceall$ function (replacing all occurrences).

%Each use conjunction, disjunction, regular constraints, and concatenation.
%The \slogbenchr\ sub-suite contains 3,391 instances \zhilin{the number to be checked}, while \slogbenchra\ sub-suite contains 120 instances \zhilin{the number to be checked}.

The third benchmark suite is the {\pyexbench} suite from \cite{ReynoldsWBBLT17}, which comprises 25,421 instances. 
This suite is derived from the PyEx tool, a symbolic executor for Python programs. The {\pyexbench} suite was generated by the CVC4 group on four popular Python packages: httplib2, pip, pymongo, and requests. These instances use regular constraints, concatenation, $\length$, $\substring$, and $\indexof$ functions. Moreover, in  \cite{ReynoldsWBBLT17}, the {\pyexbench} suite is further divided into the three sub-suites: {\pyextdbench} comprising 5,569 instances, {\pyexztbench} comprising 8,414 instances, and {\pyexzzbench} comprising 11,438 instances.

The fourth benchmark suite {\kaluzabench} is the well-known Kaluza benchmark suite~\cite{Berkeley-JavaScript}.
{\kaluzabench} contains 47,284 instances, which use regular constraints, concatenation, and $\length$ function.





\subsection{Experimental results}

The experiments are executed on a virtual machine with the CPU \zhilin{xxx} and 2GB main memory, with the timeout period set as 30 seconds. The experimental results are summarised in Table~\ref{tab-experiment}.

{\zthreetrau} does not support replace/replaceall.

%From the experimental results, we can see that \ostrich+ is the only solver that 



\definecolor{Gray}{gray}{0.9}
%\newcolumntype{g}{>{\columncolor{Gray}}c}
\begin{table}[htbp]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
& &  \cvc & \zthree & \trauplus & \zthreetrau & \ostrich+\\
\hline
\multirow{4}{*}{\transducerbench+(91)} & \cellcolor{Gray} sat &  \cellcolor{Gray}$-$ & \cellcolor{Gray}$-$ & \cellcolor{Gray} & \cellcolor{Gray}$-$ & \cellcolor{Gray}\\
\cline{2-7}
 & unsat &$-$  &$-$ &  &$-$ &\\
\cline{2-7}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray}$-$ & \cellcolor{Gray}$-$ &  \cellcolor{Gray} &\cellcolor{Gray}$-$ &\cellcolor{Gray} \\
\cline{2-7}
 & error/unknown &$-$    &$-$  &  &$-$ &\\
\hline
\multirow{4}{*}{\slogbenchr(3391)} & \cellcolor{Gray} sat &  \cellcolor{Gray}1195 & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray}$-$ & \cellcolor{Gray} \\
\cline{2-7}
 & unsat & 255 &   &  &$-$ &\\
\cline{2-7}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray}1971 &  \cellcolor{Gray} & \cellcolor{Gray} &\cellcolor{Gray}$-$ &\cellcolor{Gray} \\
\cline{2-7}
 & error/unknown &0  &    &  &$-$ &\\
\hline
\multirow{4}{*}{\slogbenchra(120)} & \cellcolor{Gray} sat &  \cellcolor{Gray} 47 & \cellcolor{Gray}$-$ & \cellcolor{Gray} & \cellcolor{Gray}$-$  & \cellcolor{Gray}\\
\cline{2-7}
 & unsat & 3 &$-$   &  &$-$ &\\
\cline{2-7}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray} 70 & \cellcolor{Gray}$-$ & \cellcolor{Gray} &\cellcolor{Gray}$-$  &\cellcolor{Gray} \\
\cline{2-7}
 & error/unknown & 0  &$-$  &  &$-$ &\\
\hline
\multirow{4}{*}{\pyextdbench(5569)} & \cellcolor{Gray} sat & \cellcolor{Gray} 4224 & \cellcolor{Gray} 4068 &  \cellcolor{Gray} & \cellcolor{Gray} 4266 & \cellcolor{Gray}\\
\cline{2-7}
 & unsat & 1284 & 1289 &    & 1295 &\\
\cline{2-7}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray} 61 & \cellcolor{Gray} 212 & \cellcolor{Gray} &\cellcolor{Gray} 8 &\cellcolor{Gray} \\
\cline{2-7}
 & error/unknown & 0 & 0   &  & 0 &\\
\hline
\multirow{4}{*}{\pyexztbench(8414)} & \cellcolor{Gray} sat & \cellcolor{Gray} 6346 & \cellcolor{Gray} 6040 & \cellcolor{Gray} & \cellcolor{Gray}7003 & \cellcolor{Gray}\\
\cline{2-7}
 & unsat & 1358  & 1370 &    &1394 &\\
\cline{2-7}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray} 710 & \cellcolor{Gray} 1004 &  \cellcolor{Gray} &\cellcolor{Gray} 17 &\cellcolor{Gray} \\
\cline{2-7}
 & error/unknown & 0 &  0   &  & 0 &\\
\hline
\multirow{4}{*}{\pyexzzbench(11438)} & \cellcolor{Gray} sat & \cellcolor{Gray} 10078 & \cellcolor{Gray} 8804 & \cellcolor{Gray} & \cellcolor{Gray} 10129 & \cellcolor{Gray}\\
\cline{2-7}
 & unsat & 1204 & 1207 &  &   1222 &\\
\cline{2-7}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray} 156 & \cellcolor{Gray} 1427 & \cellcolor{Gray} &\cellcolor{Gray} 87& \cellcolor{Gray} \\
\cline{2-7}
 & error/unknown & 0 & 0  &  & 0 &\\
\hline
\multirow{4}{*}{\kaluzabench(47284)} & \cellcolor{Gray} sat &  \cellcolor{Gray} 35264 & \cellcolor{Gray} 33438 & \cellcolor{Gray} & \cellcolor{Gray} 34769 & \cellcolor{Gray}\\
\cline{2-7}
 & unsat & 12014 &  11799 &    &12014  &\\
\cline{2-7}
 & \cellcolor{Gray}  timeout & \cellcolor{Gray} 6 & \cellcolor{Gray} 2047 &  \cellcolor{Gray} &\cellcolor{Gray} 501 &\cellcolor{Gray} \\
\cline{2-7}
 & error/unknown & 0 &  0 &    & 0 &\\
\hline
\multirow{2}{*}{Total(76,307)} & \cellcolor{Gray} solved & \cellcolor{Gray}  & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray}\\
\cline{2-7}
 & \cellcolor{Gray}  unsolved & \cellcolor{Gray} &  \cellcolor{Gray} & \cellcolor{Gray} &\cellcolor{Gray} &\cellcolor{Gray} \\
\hline
\end{tabular}
\end{center}
\caption{Comparison of OSTRICH+ with the other solvers, with timeout period 30 seconds.}
\label{tab-experiment}
\end{table}%